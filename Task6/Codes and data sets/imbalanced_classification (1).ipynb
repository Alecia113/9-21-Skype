{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imbalanced_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swGhIdVldRbI"
      },
      "source": [
        "# Imbalanced classification: credit card fraud detection\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2019/05/28<br>\n",
        "**Last modified:** 2020/04/17<br>\n",
        "**Description:** Demonstration of how to handle highly imbalanced classification problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30iR3YLTdRbL"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example looks at the\n",
        "[Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud/)\n",
        "dataset to demonstrate how\n",
        "to train a classification model on data with highly imbalanced classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZXZaQkmdRbM"
      },
      "source": [
        "## First, vectorize the CSV data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehv14yF7eV1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53882e30-e7dc-4528-c1f3-99d13fe58d1e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaFlLcQmdRbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34efe87-f230-4830-9ee4-6688cb2cf5f7"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
        "fname = \"/content/drive/MyDrive/提前准备cap4/task6/creditcard.csv\"\n",
        "\n",
        "all_features = []\n",
        "all_targets = []\n",
        "with open(fname) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i == 0:\n",
        "            print(\"HEADER:\", line.strip())\n",
        "            continue  # Skip header\n",
        "        fields = line.strip().split(\",\")\n",
        "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
        "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
        "        if i == 1:\n",
        "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
        "\n",
        "features = np.array(all_features, dtype=\"float32\")\n",
        "targets = np.array(all_targets, dtype=\"uint8\")\n",
        "print(\"features.shape:\", features.shape)\n",
        "print(\"targets.shape:\", targets.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
            "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
            "features.shape: (284807, 30)\n",
            "targets.shape: (284807, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8IrYH3GdRbO"
      },
      "source": [
        "## Prepare a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6s1hHnldRbO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2bd0363-866d-4a1f-f982-696bc0d1b1b9"
      },
      "source": [
        "num_val_samples = int(len(features) * 0.2)\n",
        "train_features = features[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_features = features[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "print(\"Number of training samples:\", len(train_features))\n",
        "print(\"Number of validation samples:\", len(val_features))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 227846\n",
            "Number of validation samples: 56961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdZZ0J6IdRbP"
      },
      "source": [
        "## Analyze class imbalance in the targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oud3rXtwdRbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e106d8-038a-475b-c67c-dd160dbc597b"
      },
      "source": [
        "counts = np.bincount(train_targets[:, 0])\n",
        "print(\n",
        "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
        "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
        "    )\n",
        ")\n",
        "\n",
        "weight_for_0 = 1.0 / counts[0]\n",
        "weight_for_1 = 1.0 / counts[1]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive samples in training data: 417 (0.18% of total)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CmCQxJDdRbQ"
      },
      "source": [
        "## Normalize the data using training set statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21_ZbOf3dRbR"
      },
      "source": [
        "mean = np.mean(train_features, axis=0)\n",
        "train_features -= mean\n",
        "val_features -= mean\n",
        "std = np.std(train_features, axis=0)\n",
        "train_features /= std\n",
        "val_features /= std\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IuThgj0dRbR"
      },
      "source": [
        "## Build a binary classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn6Nwe2DdRbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba3fef1-2fe5-4337-ebd5-fadd9231dcce"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Dense(\n",
        "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
        "        ),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               7936      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139,777\n",
            "Trainable params: 139,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flNR4Xk5dRbS"
      },
      "source": [
        "## Train the model with `class_weight` argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvuWFcLTdRbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fbc2363-b54d-4f95-a0d2-b282ac5fdfc9"
      },
      "source": [
        "metrics = [\n",
        "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "    keras.metrics.FalsePositives(name=\"fp\"),\n",
        "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "    keras.metrics.TruePositives(name=\"tp\"),\n",
        "    keras.metrics.Precision(name=\"precision\"),\n",
        "    keras.metrics.Recall(name=\"recall\"),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "model.fit(\n",
        "    train_features,\n",
        "    train_targets,\n",
        "    batch_size=2048,\n",
        "    epochs=30,\n",
        "    verbose=2,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(val_features, val_targets),\n",
        "    class_weight=class_weight,\n",
        ")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "112/112 - 8s - loss: 2.2256e-06 - fn: 45.0000 - fp: 26519.0000 - tn: 200910.0000 - tp: 372.0000 - precision: 0.0138 - recall: 0.8921 - val_loss: 0.1497 - val_fn: 6.0000 - val_fp: 2847.0000 - val_tn: 54039.0000 - val_tp: 69.0000 - val_precision: 0.0237 - val_recall: 0.9200 - 8s/epoch - 73ms/step\n",
            "Epoch 2/30\n",
            "112/112 - 6s - loss: 1.4791e-06 - fn: 31.0000 - fp: 8477.0000 - tn: 218952.0000 - tp: 386.0000 - precision: 0.0436 - recall: 0.9257 - val_loss: 0.0904 - val_fn: 11.0000 - val_fp: 480.0000 - val_tn: 56406.0000 - val_tp: 64.0000 - val_precision: 0.1176 - val_recall: 0.8533 - 6s/epoch - 50ms/step\n",
            "Epoch 3/30\n",
            "112/112 - 6s - loss: 1.2320e-06 - fn: 31.0000 - fp: 6505.0000 - tn: 220924.0000 - tp: 386.0000 - precision: 0.0560 - recall: 0.9257 - val_loss: 0.0660 - val_fn: 7.0000 - val_fp: 961.0000 - val_tn: 55925.0000 - val_tp: 68.0000 - val_precision: 0.0661 - val_recall: 0.9067 - 6s/epoch - 51ms/step\n",
            "Epoch 4/30\n",
            "112/112 - 6s - loss: 9.8755e-07 - fn: 26.0000 - fp: 7725.0000 - tn: 219704.0000 - tp: 391.0000 - precision: 0.0482 - recall: 0.9376 - val_loss: 0.0871 - val_fn: 7.0000 - val_fp: 1328.0000 - val_tn: 55558.0000 - val_tp: 68.0000 - val_precision: 0.0487 - val_recall: 0.9067 - 6s/epoch - 50ms/step\n",
            "Epoch 5/30\n",
            "112/112 - 6s - loss: 8.9502e-07 - fn: 18.0000 - fp: 6353.0000 - tn: 221076.0000 - tp: 399.0000 - precision: 0.0591 - recall: 0.9568 - val_loss: 0.0373 - val_fn: 9.0000 - val_fp: 604.0000 - val_tn: 56282.0000 - val_tp: 66.0000 - val_precision: 0.0985 - val_recall: 0.8800 - 6s/epoch - 51ms/step\n",
            "Epoch 6/30\n",
            "112/112 - 6s - loss: 7.7045e-07 - fn: 14.0000 - fp: 6688.0000 - tn: 220741.0000 - tp: 403.0000 - precision: 0.0568 - recall: 0.9664 - val_loss: 0.0766 - val_fn: 7.0000 - val_fp: 1748.0000 - val_tn: 55138.0000 - val_tp: 68.0000 - val_precision: 0.0374 - val_recall: 0.9067 - 6s/epoch - 50ms/step\n",
            "Epoch 7/30\n",
            "112/112 - 6s - loss: 8.0255e-07 - fn: 19.0000 - fp: 6924.0000 - tn: 220505.0000 - tp: 398.0000 - precision: 0.0544 - recall: 0.9544 - val_loss: 0.1086 - val_fn: 5.0000 - val_fp: 2293.0000 - val_tn: 54593.0000 - val_tp: 70.0000 - val_precision: 0.0296 - val_recall: 0.9333 - 6s/epoch - 50ms/step\n",
            "Epoch 8/30\n",
            "112/112 - 6s - loss: 5.9733e-07 - fn: 13.0000 - fp: 6435.0000 - tn: 220994.0000 - tp: 404.0000 - precision: 0.0591 - recall: 0.9688 - val_loss: 0.0227 - val_fn: 12.0000 - val_fp: 335.0000 - val_tn: 56551.0000 - val_tp: 63.0000 - val_precision: 0.1583 - val_recall: 0.8400 - 6s/epoch - 50ms/step\n",
            "Epoch 9/30\n",
            "112/112 - 6s - loss: 6.5717e-07 - fn: 11.0000 - fp: 6343.0000 - tn: 221086.0000 - tp: 406.0000 - precision: 0.0602 - recall: 0.9736 - val_loss: 0.1305 - val_fn: 6.0000 - val_fp: 2387.0000 - val_tn: 54499.0000 - val_tp: 69.0000 - val_precision: 0.0281 - val_recall: 0.9200 - 6s/epoch - 51ms/step\n",
            "Epoch 10/30\n",
            "112/112 - 6s - loss: 8.4042e-07 - fn: 14.0000 - fp: 7450.0000 - tn: 219979.0000 - tp: 403.0000 - precision: 0.0513 - recall: 0.9664 - val_loss: 0.0185 - val_fn: 11.0000 - val_fp: 215.0000 - val_tn: 56671.0000 - val_tp: 64.0000 - val_precision: 0.2294 - val_recall: 0.8533 - 6s/epoch - 50ms/step\n",
            "Epoch 11/30\n",
            "112/112 - 6s - loss: 5.9574e-07 - fn: 11.0000 - fp: 5873.0000 - tn: 221556.0000 - tp: 406.0000 - precision: 0.0647 - recall: 0.9736 - val_loss: 0.0450 - val_fn: 9.0000 - val_fp: 879.0000 - val_tn: 56007.0000 - val_tp: 66.0000 - val_precision: 0.0698 - val_recall: 0.8800 - 6s/epoch - 50ms/step\n",
            "Epoch 12/30\n",
            "112/112 - 6s - loss: 5.6428e-07 - fn: 9.0000 - fp: 6290.0000 - tn: 221139.0000 - tp: 408.0000 - precision: 0.0609 - recall: 0.9784 - val_loss: 0.1996 - val_fn: 3.0000 - val_fp: 5110.0000 - val_tn: 51776.0000 - val_tp: 72.0000 - val_precision: 0.0139 - val_recall: 0.9600 - 6s/epoch - 50ms/step\n",
            "Epoch 13/30\n",
            "112/112 - 6s - loss: 6.0347e-07 - fn: 11.0000 - fp: 6248.0000 - tn: 221181.0000 - tp: 406.0000 - precision: 0.0610 - recall: 0.9736 - val_loss: 0.0494 - val_fn: 7.0000 - val_fp: 920.0000 - val_tn: 55966.0000 - val_tp: 68.0000 - val_precision: 0.0688 - val_recall: 0.9067 - 6s/epoch - 50ms/step\n",
            "Epoch 14/30\n",
            "112/112 - 6s - loss: 9.7437e-07 - fn: 15.0000 - fp: 9240.0000 - tn: 218189.0000 - tp: 402.0000 - precision: 0.0417 - recall: 0.9640 - val_loss: 0.0329 - val_fn: 8.0000 - val_fp: 463.0000 - val_tn: 56423.0000 - val_tp: 67.0000 - val_precision: 0.1264 - val_recall: 0.8933 - 6s/epoch - 50ms/step\n",
            "Epoch 15/30\n",
            "112/112 - 6s - loss: 5.6393e-07 - fn: 12.0000 - fp: 5200.0000 - tn: 222229.0000 - tp: 405.0000 - precision: 0.0723 - recall: 0.9712 - val_loss: 0.0570 - val_fn: 7.0000 - val_fp: 1357.0000 - val_tn: 55529.0000 - val_tp: 68.0000 - val_precision: 0.0477 - val_recall: 0.9067 - 6s/epoch - 50ms/step\n",
            "Epoch 16/30\n",
            "112/112 - 6s - loss: 4.8788e-07 - fn: 5.0000 - fp: 5195.0000 - tn: 222234.0000 - tp: 412.0000 - precision: 0.0735 - recall: 0.9880 - val_loss: 0.0788 - val_fn: 6.0000 - val_fp: 1899.0000 - val_tn: 54987.0000 - val_tp: 69.0000 - val_precision: 0.0351 - val_recall: 0.9200 - 6s/epoch - 50ms/step\n",
            "Epoch 17/30\n",
            "112/112 - 6s - loss: 4.7291e-07 - fn: 7.0000 - fp: 5541.0000 - tn: 221888.0000 - tp: 410.0000 - precision: 0.0689 - recall: 0.9832 - val_loss: 0.1116 - val_fn: 6.0000 - val_fp: 2508.0000 - val_tn: 54378.0000 - val_tp: 69.0000 - val_precision: 0.0268 - val_recall: 0.9200 - 6s/epoch - 50ms/step\n",
            "Epoch 18/30\n",
            "112/112 - 6s - loss: 3.9056e-07 - fn: 5.0000 - fp: 4892.0000 - tn: 222537.0000 - tp: 412.0000 - precision: 0.0777 - recall: 0.9880 - val_loss: 0.0247 - val_fn: 10.0000 - val_fp: 543.0000 - val_tn: 56343.0000 - val_tp: 65.0000 - val_precision: 0.1069 - val_recall: 0.8667 - 6s/epoch - 50ms/step\n",
            "Epoch 19/30\n",
            "112/112 - 6s - loss: 6.3431e-07 - fn: 5.0000 - fp: 5982.0000 - tn: 221447.0000 - tp: 412.0000 - precision: 0.0644 - recall: 0.9880 - val_loss: 0.0360 - val_fn: 16.0000 - val_fp: 531.0000 - val_tn: 56355.0000 - val_tp: 59.0000 - val_precision: 0.1000 - val_recall: 0.7867 - 6s/epoch - 50ms/step\n",
            "Epoch 20/30\n",
            "112/112 - 6s - loss: 9.9940e-07 - fn: 19.0000 - fp: 7335.0000 - tn: 220094.0000 - tp: 398.0000 - precision: 0.0515 - recall: 0.9544 - val_loss: 0.3379 - val_fn: 6.0000 - val_fp: 3510.0000 - val_tn: 53376.0000 - val_tp: 69.0000 - val_precision: 0.0193 - val_recall: 0.9200 - 6s/epoch - 50ms/step\n",
            "Epoch 21/30\n",
            "112/112 - 6s - loss: 1.1207e-06 - fn: 13.0000 - fp: 6814.0000 - tn: 220615.0000 - tp: 404.0000 - precision: 0.0560 - recall: 0.9688 - val_loss: 0.1131 - val_fn: 8.0000 - val_fp: 1653.0000 - val_tn: 55233.0000 - val_tp: 67.0000 - val_precision: 0.0390 - val_recall: 0.8933 - 6s/epoch - 50ms/step\n",
            "Epoch 22/30\n",
            "112/112 - 6s - loss: 1.8626e-06 - fn: 14.0000 - fp: 5970.0000 - tn: 221459.0000 - tp: 403.0000 - precision: 0.0632 - recall: 0.9664 - val_loss: 0.1001 - val_fn: 9.0000 - val_fp: 742.0000 - val_tn: 56144.0000 - val_tp: 66.0000 - val_precision: 0.0817 - val_recall: 0.8800 - 6s/epoch - 51ms/step\n",
            "Epoch 23/30\n",
            "112/112 - 6s - loss: 1.8037e-06 - fn: 16.0000 - fp: 4980.0000 - tn: 222449.0000 - tp: 401.0000 - precision: 0.0745 - recall: 0.9616 - val_loss: 0.0338 - val_fn: 9.0000 - val_fp: 397.0000 - val_tn: 56489.0000 - val_tp: 66.0000 - val_precision: 0.1425 - val_recall: 0.8800 - 6s/epoch - 50ms/step\n",
            "Epoch 24/30\n",
            "112/112 - 6s - loss: 5.4342e-07 - fn: 8.0000 - fp: 4614.0000 - tn: 222815.0000 - tp: 409.0000 - precision: 0.0814 - recall: 0.9808 - val_loss: 0.0202 - val_fn: 7.0000 - val_fp: 400.0000 - val_tn: 56486.0000 - val_tp: 68.0000 - val_precision: 0.1453 - val_recall: 0.9067 - 6s/epoch - 50ms/step\n",
            "Epoch 25/30\n",
            "112/112 - 6s - loss: 6.1341e-07 - fn: 10.0000 - fp: 5551.0000 - tn: 221878.0000 - tp: 407.0000 - precision: 0.0683 - recall: 0.9760 - val_loss: 0.0938 - val_fn: 6.0000 - val_fp: 2391.0000 - val_tn: 54495.0000 - val_tp: 69.0000 - val_precision: 0.0280 - val_recall: 0.9200 - 6s/epoch - 50ms/step\n",
            "Epoch 26/30\n",
            "112/112 - 6s - loss: 7.2669e-07 - fn: 6.0000 - fp: 5829.0000 - tn: 221600.0000 - tp: 411.0000 - precision: 0.0659 - recall: 0.9856 - val_loss: 0.0511 - val_fn: 10.0000 - val_fp: 809.0000 - val_tn: 56077.0000 - val_tp: 65.0000 - val_precision: 0.0744 - val_recall: 0.8667 - 6s/epoch - 50ms/step\n",
            "Epoch 27/30\n",
            "112/112 - 6s - loss: 4.9423e-07 - fn: 6.0000 - fp: 4303.0000 - tn: 223126.0000 - tp: 411.0000 - precision: 0.0872 - recall: 0.9856 - val_loss: 0.0208 - val_fn: 10.0000 - val_fp: 383.0000 - val_tn: 56503.0000 - val_tp: 65.0000 - val_precision: 0.1451 - val_recall: 0.8667 - 6s/epoch - 50ms/step\n",
            "Epoch 28/30\n",
            "112/112 - 6s - loss: 2.7660e-07 - fn: 2.0000 - fp: 2476.0000 - tn: 224953.0000 - tp: 415.0000 - precision: 0.1435 - recall: 0.9952 - val_loss: 0.0156 - val_fn: 15.0000 - val_fp: 253.0000 - val_tn: 56633.0000 - val_tp: 60.0000 - val_precision: 0.1917 - val_recall: 0.8000 - 6s/epoch - 50ms/step\n",
            "Epoch 29/30\n",
            "112/112 - 6s - loss: 2.3559e-07 - fn: 1.0000 - fp: 1969.0000 - tn: 225460.0000 - tp: 416.0000 - precision: 0.1744 - recall: 0.9976 - val_loss: 0.0165 - val_fn: 10.0000 - val_fp: 277.0000 - val_tn: 56609.0000 - val_tp: 65.0000 - val_precision: 0.1901 - val_recall: 0.8667 - 6s/epoch - 50ms/step\n",
            "Epoch 30/30\n",
            "112/112 - 6s - loss: 2.6952e-07 - fn: 1.0000 - fp: 2045.0000 - tn: 225384.0000 - tp: 416.0000 - precision: 0.1690 - recall: 0.9976 - val_loss: 0.0248 - val_fn: 10.0000 - val_fp: 276.0000 - val_tn: 56610.0000 - val_tp: 65.0000 - val_precision: 0.1906 - val_recall: 0.8667 - 6s/epoch - 50ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f42f4492d10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6kyMKbfdRbT"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "At the end of training, out of 56,961 validation transactions, we are:\n",
        "\n",
        "- Correctly identifying 66 of them as fraudulent\n",
        "- Missing 9 fraudulent transactions\n",
        "- At the cost of incorrectly flagging 441 legitimate transactions\n",
        "\n",
        "In the real world, one would put an even higher weight on class 1,\n",
        "so as to reflect that False Negatives are more costly than False Positives.\n",
        "\n",
        "Next time your credit card gets  declined in an online purchase -- this is why."
      ]
    }
  ]
}